{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабороторна робота 3\n",
    "## Абрамова Марія"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "siameseData = pd.read_csv(\"siamese_nn.csv\")\n",
    "# siameseData[\"target\"] = \"siamese neural network\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionData = pd.read_csv(\"emotion_recognition.csv\",sep=\";\")\n",
    "covidData = pd.read_csv(\"coranavirus_disease.csv\",sep=\";\")\n",
    "covidData[\"target\"] = 2\n",
    "emotionData[\"target\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Similarity has always been a key aspect in com...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Any time two element vectors are compared, man...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>But if the comparison has to be applied to mor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In these cases, a siamese neural network may b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The two neural networks are both feedforward p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>they work parallelly in tandem and compare th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The output generated by a siamese neural netwo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>In this overview we first describe the siamese...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Additionally, we list the programming language...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This section reviews existing tracking method...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Similarity has always been a key aspect in com...       1\n",
       "1  Any time two element vectors are compared, man...       1\n",
       "2  But if the comparison has to be applied to mor...       1\n",
       "3  In these cases, a siamese neural network may b...       1\n",
       "4  The two neural networks are both feedforward p...       1\n",
       "5   they work parallelly in tandem and compare th...       1\n",
       "6  The output generated by a siamese neural netwo...       1\n",
       "7  In this overview we first describe the siamese...       1\n",
       "8  Additionally, we list the programming language...       1\n",
       "9   This section reviews existing tracking method...       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siameseData.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The primary objective of Speech Emotion Recogn...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The ideal way to reach this objective, as the ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nowadays, we are at the dawn of Deep Learning ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SER is not an exception since convolutional ne...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The main advantage of DL is the fact that it r...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>The network applies a ReLU activation function...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Thus the kth filter map in each layer takes th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>We have presented a strategy for performing on...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>We outlined new results comparing the performa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Our networks outperform all available baseline...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  target\n",
       "0    The primary objective of Speech Emotion Recogn...       3\n",
       "1    The ideal way to reach this objective, as the ...       3\n",
       "2    Nowadays, we are at the dawn of Deep Learning ...       3\n",
       "3    SER is not an exception since convolutional ne...       3\n",
       "4    The main advantage of DL is the fact that it r...       3\n",
       "..                                                 ...     ...\n",
       "295  The network applies a ReLU activation function...       1\n",
       "296  Thus the kth filter map in each layer takes th...       1\n",
       "297  We have presented a strategy for performing on...       1\n",
       "298  We outlined new results comparing the performa...       1\n",
       "299  Our networks outperform all available baseline...       1\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat([emotionData,covidData, siameseData], ignore_index=True )\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle training dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>In order to demonstrate the high effectivennes...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>In this experimental work, we have used Multiv...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Hao has constructed the ensemble predictor of ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>. After the last convolutional layer we divide...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Speech is the main and direct means of transmi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Region-wise this distribution depicts total de...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>. It contains 535 utterances spoken by 10 acto...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The main advantage of DL is the fact that it r...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>The researchers are still debating for what fe...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>In addition, the introduced method learns to g...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  target\n",
       "39   In order to demonstrate the high effectivennes...       3\n",
       "38   In this experimental work, we have used Multiv...       3\n",
       "183  Hao has constructed the ensemble predictor of ...       2\n",
       "13   . After the last convolutional layer we divide...       3\n",
       "90   Speech is the main and direct means of transmi...       3\n",
       "165  Region-wise this distribution depicts total de...       2\n",
       "44   . It contains 535 utterances spoken by 10 acto...       3\n",
       "4    The main advantage of DL is the fact that it r...       3\n",
       "57   The researchers are still debating for what fe...       3\n",
       "149  In addition, the introduced method learns to g...       2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_shuffle=train_df.sample(frac=1,random_state=9) \n",
    "train_shuffle.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    100\n",
       "2    100\n",
       "1    100\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_shuffle.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 30, 270, 30)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences, test_sentences, train_labels,test_labels = train_test_split(\n",
    "    train_shuffle['text'].to_numpy(),\n",
    "    train_shuffle['target'].to_numpy(),\n",
    "    test_size=0.1, \n",
    "    random_state=40\n",
    ")\n",
    "\n",
    "len(train_sentences),len(test_sentences),len(train_labels),len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting text into numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# avg len of sent\n",
    "max_sq_len = round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))\n",
    "max_sq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 17:54:10.539109: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-11-18 17:54:10.592881: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-18 17:54:10.593029: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (mariia-HP-ProBook-430-G2): /proc/driver/nvidia/version does not exist\n",
      "2021-11-18 17:54:10.593711: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "text_vectorizer = TextVectorization(max_tokens=10000,  #number of word in vocabulary\n",
    "                                    standardize=\"lower_and_strip_punctuation\", \n",
    "                                    split =\"whitespace\",\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_sq_len,\n",
    "                                    pad_to_max_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 17:54:10.979157: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Embedding\n",
    "\n",
    "embedding = Embedding(\n",
    "                        input_dim=10000, \n",
    "                        output_dim=128, \n",
    "                        input_length=max_sq_len, \n",
    "                        name = 'embeding_1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In addition to asymptomatic infection, SARS-CoV-2 virus, the disease’s etiological agent, is capable of producing acute respiratory syndrome, varying between mild cases (around 80%) to very severe cases (between 5% and 10%), which develop respiratory insufficiency and require medical care in hospital. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 24, 128), dtype=float32, numpy=\n",
       "array([[[-0.02726536,  0.00975678,  0.00276816, ..., -0.00205692,\n",
       "          0.03157706,  0.04043994],\n",
       "        [ 0.047692  , -0.03201105,  0.03351451, ...,  0.04547742,\n",
       "         -0.00546256, -0.04595573],\n",
       "        [-0.02897015, -0.02936975,  0.00482843, ..., -0.02307955,\n",
       "         -0.02342745, -0.03784245],\n",
       "        ...,\n",
       "        [ 0.04430914, -0.00957718, -0.04431483, ...,  0.01402852,\n",
       "          0.03528208, -0.00907106],\n",
       "        [ 0.01899046,  0.03779479,  0.00416166, ...,  0.04132314,\n",
       "         -0.02292631, -0.0364764 ],\n",
       "        [ 0.0203934 ,  0.03986657,  0.00136803, ..., -0.01176503,\n",
       "          0.01919306, -0.0465233 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_text = random.choice(train_sentences)\n",
    "print(random_text)\n",
    "sample_embed = embedding(text_vectorizer([random_text]))\n",
    "sample_embed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function to evaluate: accuracy, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "  \"\"\"\n",
    "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
    "\n",
    "  Args:\n",
    "  -----\n",
    "  y_true = true labels in the form of a 1D array\n",
    "  y_pred = predicted labels in the form of a 1D array\n",
    "\n",
    "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
    "  \"\"\"\n",
    "  # Calculate model accuracy\n",
    "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
    "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "  model_results = {\"accuracy\": model_accuracy,\n",
    "                  \"precision\": model_precision,\n",
    "                  \"recall\": model_recall,\n",
    "                  \"f1\": model_f1}\n",
    "  return model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 0: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0= Pipeline([ \n",
    "    (\"tfidf\",TfidfVectorizer()), \n",
    "    (\"clf\", MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.fit(train_sentences,train_labels)\n",
    "y_hat0=model_0.predict(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_score= model_0.score(test_sentences,test_labels)\n",
    "\n",
    "baseline_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 96.66666666666667,\n",
       " 'precision': 0.9694444444444444,\n",
       " 'recall': 0.9666666666666667,\n",
       " 'f1': 0.9664109121909632}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_results(test_labels,y_hat0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 24, 128), dtype=float32, numpy=\n",
       "array([[[-0.07142892,  0.05905135, -0.04300959, ..., -0.05127347,\n",
       "          0.08046202, -0.00239245],\n",
       "        [ 0.02947135, -0.01375762,  0.01498308, ...,  0.0268305 ,\n",
       "          0.01335344, -0.06382021],\n",
       "        [-0.07319129,  0.02022594, -0.04089615, ..., -0.07241718,\n",
       "          0.02536135, -0.08075272],\n",
       "        ...,\n",
       "        [ 0.00753059,  0.03182925, -0.08248116, ..., -0.02725436,\n",
       "          0.07600991, -0.04474253],\n",
       "        [ 0.00519415,  0.05171209, -0.00996297, ...,  0.02707604,\n",
       "         -0.00852028, -0.04991342],\n",
       "        [ 0.0023114 ,  0.06064826, -0.01731135, ..., -0.03225316,\n",
       "          0.03919969, -0.0639346 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = embedding(text_vectorizer([random_text]))\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Feed forward NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "#x = layers.Dense(256, input_shape=(784,), activation=\"sigmoid\")(x)\n",
    "#x = layers.Dense(128, activation=\"sigmoid\")(x)\n",
    "x = layers.GlobalAveragePooling1D()(x) \n",
    "outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "model_1 = tf.keras.Model(inputs,outputs,name=\"model_1_dense\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "embeding_1 (Embedding)       (None, 24, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "9/9 [==============================] - 2s 89ms/step - loss: 0.0000e+00 - accuracy: 0.3333 - val_loss: 0.0000e+00 - val_accuracy: 0.3333\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 0.3333 - val_loss: 0.0000e+00 - val_accuracy: 0.3333\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0000e+00 - accuracy: 0.3333 - val_loss: 0.0000e+00 - val_accuracy: 0.3333\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.0000e+00 - accuracy: 0.3333 - val_loss: 0.0000e+00 - val_accuracy: 0.3333\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0000e+00 - accuracy: 0.3333 - val_loss: 0.0000e+00 - val_accuracy: 0.3333\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_1_history = model_1.fit(train_sentences,train_labels, epochs=5,validation_data=(test_sentences,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\") # inputs are 1-dimensional strings\n",
    "x = text_vectorizer(inputs) # turn the input text into numbers\n",
    "x = embedding(x) # create an embedding of the numerized numbers\n",
    "x = layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embedding (try running the model without this layer and see what happens)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # create the output layer, want binary outputs so use sigmoid activation\n",
    "model_1_5 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_1_5.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization_3 (TextVe (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "embeding_1 (Embedding)       (None, 24, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_5 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get a summary of the model\n",
    "model_1_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "9/9 [==============================] - 2s 81ms/step - loss: 0.5840 - accuracy: 0.3333 - val_loss: 0.4911 - val_accuracy: 0.3333\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.4010 - accuracy: 0.3333 - val_loss: 0.3284 - val_accuracy: 0.3333\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2240 - accuracy: 0.3333 - val_loss: 0.1641 - val_accuracy: 0.3333\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0466 - accuracy: 0.3333 - val_loss: -0.0058 - val_accuracy: 0.3333\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - 0s 44ms/step - loss: -0.1395 - accuracy: 0.3333 - val_loss: -0.1814 - val_accuracy: 0.3333\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_1_history = model_1_5.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(test_sentences, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6420795 ],\n",
       "       [0.67691565],\n",
       "       [0.62670267],\n",
       "       [0.6556613 ],\n",
       "       [0.6573303 ],\n",
       "       [0.6160018 ],\n",
       "       [0.5897418 ],\n",
       "       [0.6404785 ],\n",
       "       [0.6620507 ],\n",
       "       [0.5861466 ]], dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions (these come back in the form of probabilities)\n",
    "model_1_pred_probs = model_1_5.predict(test_sentences)\n",
    "model_1_pred_probs[:10] "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "084a917606a6861dbe14d7cb67babe6a4c9c1ed8eedead555d116d638f8782d0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('my_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
